{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rF2x3qooyBTI"
   },
   "source": [
    "# 심층 합성곱 생성적 적대 신경망 (Deep Convolutional Generative Adversarial Networks, DCGAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2MbKJY38Puy9"
   },
   "source": [
    "## 생성적 적대 신경망(GANs) \n",
    "\n",
    "- [생성적 적대 신경망](https://arxiv.org/abs/1406.2661) (Generative Adversarial Networks, GANs)은 요즘 컴퓨터 과학에서 가장 흥미로운 아이디어 중 하나  \n",
    "- 두개의 모델이 적대적인 과정을 통해 동시에 훈련  \n",
    "- *생성자* (\"예술가\")는 진짜처럼 보이는 이미지를 생성하도록 배우는 와중에, *감별자* (\"예술비평가\")는 가짜의 이미지로부터 진짜를 구별하게 되는 것을 배우게 됨\n",
    "\n",
    "![생성자와 감별자를 그린 도표](https://tensorflow.org/tutorials/generative/images/gan1.png)\n",
    "\n",
    "\n",
    "\n",
    "- 훈련과정 동안 *생성자*는 점차 실제같은 이미지를 더 잘 생성  \n",
    "- *감별자*는 점차 진짜와 가짜를 더 잘 구별  \n",
    "- 이 과정은 *감별자*가 가짜 이미지에서 진짜 이미지를 더이상 구별하지 못하게 될때, 평형상태에 도달\n",
    "\n",
    "![생성자와 감별자를 그린 두번째 도표](https://tensorflow.org/tutorials/generative/images/gan2.png)\n",
    "\n",
    "- 이 과정을 MNIST 데이터를 이용하여 구현  \n",
    "- 아래의 애니메이션은 50 에포크(epoch)동안 훈련한 *생성자*가 생성해낸 연속된 이미지들을 보여줌  \n",
    "- 이미지들은 랜덤한 잡음으로 부터 시작되었고, 점차 시간이 지남에 따라 손으로 쓴 숫자들을 닮아가게 됨\n",
    "\n",
    "![출력 예시](https://tensorflow.org/images/gan/dcgan.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WZKbyU2-AiY-"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wx-zNbLqB4K8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YzTlj4YdCip_"
   },
   "outputs": [],
   "source": [
    "# GIF를 만들기위해 설치\n",
    "#!pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "#import glob\n",
    "#import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iYn4MdZnKCey"
   },
   "source": [
    "### 데이터셋 로딩 및 준비\n",
    "- 생성자와 감별자를 훈련하기위해 MNIST 데이터셋을 사용  \n",
    "- 생성자는 손글씨 숫자 데이터를 닮은 숫자들을 생성할 것임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a4fYMGxGhrna"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mnist dataset load\n",
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "#(train_images, train_labels), (_, _) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NFC2ghIdiZYE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# 이미지에 dimension 더해주고 [-1, 1]로 정규화\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5 \n",
    "\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S4PIDhoDLbsZ"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-yKCCQOoJ7cn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (None, 28, 28, 1), types: tf.float32>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 배치를 만들고 섞음\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7pxv2sUnnm3U"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2af5aee4108>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[100].reshape(28, 28), cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "THY-sZMiQ4UV"
   },
   "source": [
    "## 모델 만들기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-tEyxE-GMC48"
   },
   "source": [
    "### 생성자\n",
    "\n",
    "- 생성자는 시드값 (seed; 랜덤한 잡음)으로부터 CNN 의 역순으로 이미지를 생성하기 위해, `tf.keras.layers.Conv2DTranspose` (inverse Convolution 을 통한 upsampling) 층을 이용  \n",
    "- stride=(2, 2) 일 경우 dimension 이 2 배로 upsampling 됨\n",
    "- 처음 `Dense`층은 시드값을 인풋으로 받음  \n",
    "- 그 다음 원하는 사이즈 28x28x1의 이미지가 나오도록 Conv2DTranspose 를 이용한 업샘플링을 여러번 함  \n",
    "- tanh를 사용하는 마지막 층을 제외한 나머지 각 층마다 활성함수로 `tf.keras.layers.LeakyReLU`을 사용하고 있음을 주목할 것\n",
    "\n",
    "<img src=\"GAN_Generator.png\" width=\"700\">\n",
    "\n",
    "- \"same\" padding and stride = 1, the output is the same size  \n",
    "- \"same\" padding and stride = 2, the output is double the size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6bpTcDqoLWjY"
   },
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, \n",
    "                           input_shape=(100,)))   # seed 를 입력으로 받음, 출력 12544\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)          # 배치사이즈로 None 추가\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), \n",
    "                                     strides=(1, 1), padding='same', use_bias=False))  \n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), \n",
    "                                     strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), \n",
    "                                     strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GyWgG09LCSJl"
   },
   "source": [
    "(아직 훈련이 되지않은) 생성자를 이용해 이미지를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OiSikY24nm3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 12544)             1254400   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12544)             50176     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 7, 7, 128)         819200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 14, 14, 64)        204800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 28, 28, 1)         1600      \n",
      "=================================================================\n",
      "Total params: 2,330,944\n",
      "Trainable params: 2,305,472\n",
      "Non-trainable params: 25,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model(input, training=False)   \n",
    "- False - inference  \n",
    "- True - training  \n",
    "\n",
    "- Some neural network layers behave differently during training and inference, for example Dropout and BatchNormalization layers. During training, dropout will randomly drop out units and correspondingly scale up activations of the remaining units. During inference, it does nothing (since you usually don't want the randomness of dropping out units here). The training argument lets the layer know which of the two \"paths\" it should take. If you set this incorrectly, your network might not behave as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gl7jcC7TdPTG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2af5793bb88>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "print(generated_image.shape)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D0IKnaCtg6WE"
   },
   "source": [
    "### 감별자 \n",
    "- 감별자는 합성곱 신경망(Convolutional Neural Network, CNN) 기반의 이미지 분류기\n",
    "- MNIST dataset 은 input_shape (28, 28, 1)  \n",
    "- sigmoid output 은 probability scalar 값  \n",
    "- CNN 과의 차이 : pooling layer 없고, stride 를 통하여 downsampling  \n",
    "\n",
    "<img src=\"GAN_Discriminator.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dw2tPLmk2pEP"
   },
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), \n",
    "                            strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(512, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QhPneagzCaQv"
   },
   "source": [
    "- (아직까지 훈련이 되지 않은) 감별자를 사용하여, 생성된 이미지가 진짜인지 가짜인지 판별  \n",
    "- 모델은 진짜 이미지에는 양수의 값 (positive values)을, 가짜 이미지에는 음수의 값 (negative values)을 출력하도록 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UxUOZ_Nbnm3h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 256)         819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 2, 2, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 4,305,409\n",
      "Trainable params: 4,305,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gDkA05NE6QMs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.00082036]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0FMYgY_mPfTi"
   },
   "source": [
    "## 손실함수와 옵티마이저 정의\n",
    "- 두 모델의 손실함수와 옵티마이저를 정의  \n",
    "- Discriminator 의 output 이 sigmoid 이므로, binary crossentropy 를 loss function 으로 사용 \n",
    "- from_logits=True 로 지정   \n",
    "\n",
    "\n",
    "- tf.keras.losses.BinaryCrossentropy()(y_true, y_pred, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "psQfmXxYKU3X"
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PKY_iPSPNWoj"
   },
   "source": [
    "### 감별자 손실함수 \n",
    "\n",
    "- 감별자가 가짜 이미지에서 얼마나 진짜 이미지를 잘 판별하는지 수치화하는 함수  \n",
    "- 진짜 이미지에 대한 감별자의 예측과 1로 이루어진 행렬을 비교하고, 가짜 (생성된) 이미지에 대한 감별자의 예측과 0으로 이루어진 행렬을 비교  \n",
    "- shape 은 (256, 1) $\\rightarrow$ BATCHSIZE\n",
    "- real image 는 label [11111..111], fake image 는 label [00000....000] 이 ground truth  \n",
    "- discriminator 는 real 은 real 로, fake 는 fake 로 바르게 판별해야 하므로 real_loss + fake_loss 가 minimize 되도록 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wkMNfBWlT-PV"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)  # [111,,,111] 과 real_output 차이\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)    # [000,,,,000] 과 fake_output 차이\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jd-3GCUEiKtv"
   },
   "source": [
    "### 생성자 손실함수\n",
    "\n",
    "- 감별자를 얼마나 잘 속였는지에 대해 수치화  \n",
    "- 직관적인 느낌으로, 생성자가 원활히 수행되고 있다면, 감별자는 가짜 이미지를 진짜 (또는 1)로 분류를 할 것임. \n",
    "- 여기서 우리는 생성된 이미지에 대한 감별자의 결정(fake_output)을 1로 이루어진 행렬과 비교를 할 것임 (감별자가 감별한 결과가 모두 1 이 되어야 생성자가 감별자를 완벽히 속인 것임)  \n",
    "\n",
    "\n",
    "- fake_output = discriminator(generated_images, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "90BIcCKcDMxz"
   },
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)  # [111,,111] 과 fake_output 차이"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MgIc7i0th_Iu"
   },
   "source": [
    "### 감별자와 생성자는 따로 훈련되기 때문에, 감별자와 생성자의 옵티마이저는 다르다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iWCn_PVdEJZ7"
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mWtinsGDPJlV"
   },
   "source": [
    "### 체크포인트 저장\n",
    "\n",
    "- optimizer 와 model 저장 \n",
    "\n",
    "\n",
    "-  tf.train.Checkpoint(optimizer=optimizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CA1w-7s2POEy"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rw1fkAczTQYh"
   },
   "source": [
    "## 훈련 루프 정의\n",
    "\n",
    "- 훈련 루프는 생성자가 입력으로 랜덤시드를 받는 것으로부터 시작  \n",
    "- 그 시드값을 사용하여 이미지를 생성  \n",
    "- 감별자를 사용하여 (훈련 세트에서 갖고온) 진짜 이미지와 (생성자가 생성해낸) 가짜이미지를 분류  \n",
    "- 각 모델의 손실을 계산하고, 그래디언트 (gradients)를 사용해 생성자와 감별자를 업데이트\n",
    "<img src=\"adverseModel.png\" width=\"500\">\n",
    "\n",
    "## Training\n",
    "\n",
    "<img src=\"GANtraining.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NS2GWywBbAWo"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# 이 시드를 시간이 지나도 재활용 (GIF 애니메이션에서 진전 내용을 시각화하는데 쉽기 때문)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3t5ibNo05jCB"
   },
   "outputs": [],
   "source": [
    "# `tf.function` 데코레이터는 함수를 \"컴파일\"\n",
    "# 두개 module 의 gradient 를 따로 tracking 함\n",
    "\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        \n",
    "        generated_images = generator(noise, training=True)     # noise 에서 fake image 생성 \n",
    "\n",
    "        real_output = discriminator(images, training=True)       # real image 에 대한 감별자의 output\n",
    "        fake_output = discriminator(generated_images, training=True)  # fake image 에 대한 감별자의 output\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)   # fake image 에 대한 감별자의 output 을 all 1 로 만들기 위한 생성자 손실함수\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)  # real image 와 fake image 의 total loss 를 minimize 하기 위한 감별자 손실함수\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)  # 손실함수와 trainable parameter 지정\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)    \n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))   # gradient update\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2M7LmLtGEMQJ"
   },
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        for image_batch in dataset:\n",
    "            train_step(image_batch)\n",
    "\n",
    "        # GIF를 위한 이미지를 바로 생성\n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_save_images(generator, epoch + 1, seed)\n",
    "\n",
    "        # 15 에포크가 지날 때마다 모델을 저장\n",
    "        if (epoch + 1) % 15 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "    \n",
    "        print (' 에포크 {} 에서 걸린 시간은 {} 초 입니다'.format(epoch +1, time.time()-start))\n",
    "        \n",
    "    # 마지막 에포크가 끝난 후 생성\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator, epochs, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2aFF7Hk3XdeW"
   },
   "source": [
    "**이미지 생성 및 저장**\n",
    "\n",
    "-`training`이 False로 맞춰진 것을 주목. 이렇게 하면 (배치정규화를 포함하여) 모든 층들이 추론 모드로 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RmdVsmvhPxyy"
   },
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    \n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dZrd4CdjR-Fp"
   },
   "source": [
    "## 모델 훈련\n",
    "- 위에 정의된 `train()` 메서드를 생성자와 감별자를 동시에 훈련하기 위해 호출  \n",
    "- 생성적 적대 신경망을 학습하는 것은 매우 까다로울 수 있dma. 생성자와 감별자가 서로를 제압하지 않는 것이 중요 (비슷한 속도로 train)\n",
    "- 훈련 초반부에는 생성된 이미지는 랜덤한 노이즈처럼 보이나 훈련이 진행될수록, 생성된 숫자는 점차 진짜처럼 보임  \n",
    "- 약 50 에포크가 지난 후, MNIST 숫자와 닮은 이미지가 생성  \n",
    "- 코랩에서 기본 설정으로 실행하면, 에포크마다 1분정도 소요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ly3UN0SLLY2l"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOwAAADnCAYAAAAdFLrXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO2deZwU1bXHv90zzOKwI4uggMgiW9gMaiS4Ia4ERVRAH099GvSpcYnGNS7x6fMlonkEFRVjYsJHBY24K+7yVGRRkACyKiIiyyD7MsxMvz8qv1s1Mz1DT09Vddd4v58Pnxl6urvurVv3nnPPOfecWCKRwGKxRIN4phtgsVhSx05YiyVC2AlrsUQIO2EtlghhJ6zFEiFya/pjPB5PAPhhSY7FYvj1Xd7vq/z/8vJycnJyACgtLY1V+WDy76pzo3T9eDxu2iGCssR7+pxSPwFycnLMmEbJQ1Dbvvoxpn6gdhcVFQHQrFkzevXqBcD69esB2Lp1KwDfffed+dyuXbuS9tNKWIslQtQoYf1cgf1ezfV9kmiVJW5YVJas3te9UjYI0rmnQbfJDyqPZdS0AS9q9+7duwFo3749u3btAqBHjx4AfPnllwCsW7fOaIfVUeOEjQJ6ADXIsVgs1MHVdSvf6JKSktDaUB+Ix+NJtxMQ3JYiTJo0aQI4z8uePXsAePPNNwEoLCwEnHuwv+fGqsQWS4SI1bR6ZcvGPV0SiUToRqdMSINU+wn+jmlubq75KakRNGGOqZ941fz9zDmgeuOalbAWS4SI/B42W6gP+6xUGTRoEABPPvkkAGvWrOHKK68EYPHixRlrVzZS3b68Ovb3HFkJa7FEiMD2sNLFZR2TczhMSWT3sFVJt6+xWIx+/foB8PbbbwNwwAEHmL9PmTIFgL/97W8ALFmyhLKyMgA2bdqUziWTEoU9rIIkevfuzY4dOwD45z//WavvqK6fganEP//5zwG4+uqrAXjhhRcAWLFiBbfccgvgRH0AdOrUicMPPxyA7du3B9WkQJDhpVu3boBrol+yZIkx0ZeWlpr3R1V1zs3N5YYbbgDcPuzcuROAtWvX0qZNG8Ad56ZNm5rPqv/5+flANHzBqZKTk8OZZ54JwKRJkwBXSO3du5f27dv7ej2rElssESIQCZuTk0PPnj0BV22SVD388MOTRiVJZW7YsCGAiQbJdlq0aAHAG2+8Abir7O7du1m2bFmF9+zdu9dIpahJmfz8fKPafvzxxxV+bt68mb59+wIwZMiQKp/VeB977LEAvPfee4G3N2gUKDNy5EgmT54MuM+6DE1ffvml7xqjlbAWS4TwVcJqZenSpQtdu3YF3FW1oKAASO5A3rdvn5FG5513HuC6DDJFKkakWCzGPffcA7j7Fp3AWLRokXnf5s2bATjnnHN46aWXADe2NCoUFRWxcuVKABo3bgxg9mcDBgygUaNGgHu/ysvLjRYxc+ZMAD744INQ2xwEei504mbMmDHs27evwnt0D3bs2FHBfuHL9f20Esvw8Je//IVOnToBmJ+azIlEwhwjOuyww8xnmzdvDkCHDh0A6NixIwBTp05N21CTjkWxNtbeBg0amAkqdUj9SKbS33zzzRx55JEAxlDhB0Faib3Hw4YNGwZAy5YtAbj++usBOPDAA834ytC2du1arrvuOsC1Kld+sNMhk1biNm3a0K5dOwAeeughwOmvrOfemGCAk046iXfeeSeta1XXT6sSWywRwheVOJnPVWqTjEnyQw0fPjypT1ZuHa1I8uENHDiQX//61340c7/U9qRPfn6+cU0lc+GIvLw8wDG8yeik+7Nt27Y6tTlovC6c119/HYCxY8cCrkbVoEED8371ddasWWbM27ZtCzhSF5yxjYJ7S5JSvtRYLGaMSBrH77//3vRZhij1bejQoWlL2Grb5Ou3WSyWQPHV6CQdvnnz5nzzzTeAazx67LHHAFdyemnXrp1ZiSofSL/rrrv8bGKN1HbVHzRokPmMAigOPfRQwAkQkaFNwQQFBQXmHiW7D9lMIpEwUqV3796A22cvGrdzzz2XPn36AK7RbcWKFQBcdtllgbfXD+TGUsDH7NmzueiiiwDX1nLhhRdy1FFHJf38zTff7HubrIS1WCKELxJWUubkk08GoG/fvsydOxeAOXPmAMkliiTQmjVrqgRTTJw4EcjuPd4zzzxTpd3/+7//Czh78e7duwNw3HHHAY5EUn+0QkfpdIvG+YQTTgCSp+XxunXk+pAkPvroowEnXHXv3r2BtzddpOVJG/rhhx8AOPHEE4077pBDDgFgxIgRVT6vvX4QwTG+qsRyZTRr1swMqiae160jH638c96B/+yzzwA3BjkbGTp0KOAYjvSAyuikwO+f//znxtwvo0Vpaanpn9REGWz8cHkESSwWM264gw46qMLfSkpKjLtK/vRWrVoxe/ZswHUDaQJke19/9rOfAW5c++DBgwHYs2ePiVrTVk0GJ3ANjnfccUdgbbMqscUSIXwNnDj44IMBx1HeuXNnwF2lPv/8c8BxssswI2kUi8WMyqzPff3117W5dFL8drLLbD9//nwAunfvbiTs999/X+Fnx44djdFi1apVADz33HOm71dddRUAxcXFgBMg8ve//x1wXWEbNmwwq3ZN4xTW8TpFKkm1lcrXpEmTpCliJI10H9SHDh06sGbNmnSaEUrgxJIlSwBMkMRtt90GwGuvvcbjjz8OuKfRvMn3NFZeN1e62MAJi6Ue4Ose9ttvvwWgZ8+eVc4I/vSnPwWcVVZ7GO378vLyzO9+SNag0Mr57LPPAnDppZea/bc0BMXX5uXlGYkit07jxo254oorADfIRAEUnTp1MqlX3n33XcCRRJLOsgFk0h2kE1iSKtImqkvNqX26pK+MjOnE14aZd1p7Vrki161bB8CoUaOqhGBqXw5u8E+QhJY1UQ97LBYzN19H0o477jhjffNmMagrQalPOgJ41113md9liNIANmjQgBdffBFwLcFjx441Kr8e3i+++AJwDj0sX75c7QYqqluaqMnGKwyVODc316jqGiO1qWnTpsaw5kUHAqT26xlYv369iZKqRbuBcEt16JrKV7V8+XJOPPFEAM4//3zAifaSkFHcvB9YldhiqQeEljUxmSm/devW5nevapHtSJq89dZbdOnSBXBinsFV6UtKSozqrNfOPvts45OU4UqRM0uXLq1yHb+PZtWFrl27VvErSgKtXr2a008/HYB58+YBjiYgt5bcfdoGvP/++7W+foZyZQHwyCOPAI4mqD5IeygpKWHWrFmhtclKWIslQmQkL7E27gqgALI68qU63njjDZPuZOrUqYDrkvH2R/vcvLw8E4+7YcMGoOJB92ymrKzM9ENIAk2bNs0YoLxRQjo/K+1JElquraggTWfVqlVcfPHFQMWTOWPGjAmtLVbCWiwRIiMSVjG2XiuoLIlRQ5JUmSeSoT3v+++/b2JQX375ZSA6aU/37Nlj2qqf999/P+CE4snNoX1tfn6+CT298MILAVfTePjhh0Nrt5906NChSpXCdANA0iUjEzZZ1rzLL788Ay0JB++BZh3Vko8yKsfsNm7caH7XpDzllFMAJ12KVGLvpNYi/NVXXwGun/KBBx5gxowZgOvjjAL9+/ev8poSGISFVYktlggRuoStXKlcyDmtrIL1kU8++cQETkQxN6+MRlILdUB9+fLl5kjZrbfeCjhS+Be/+AVQ9bQOuEY6xeRGgQEDBlR57ZJLLgm1DVbCWiwRInQJW1hYaFZcL3I+Z7KoVNDs27fPSKnnn38egGOOOSaTTUqZXbt2mf2mTmWJ/Px8hg8fDrgS84svvjDx4zqVpb5v2LCBs846C4jWeCdLTXvSSScZbSEMQp+wlX154DzIioaJwsCly/XXX8/IkSMB14ijA9DVBdBnE7JwS7VVJNcZZ5xh3qMjdYMHDzbbH/me//GPfwDw7//+7+E02GdkMPRy6aWXhtoGqxJbLBEitNM6YubMmeYYmSgrKzMnHZRt0Q+yrZZoUVGR6Z8kq1RIxRanQxindWoiJyeHP//5z4BbaiU/P9+4dRRvrdxIdSETY6qTVbt27TIqvHIuK4Ok39jTOhZLPSB0Cbtz584KiavAWaW+/PJLvy+VdRK2WbNmJiJK0kYxxUceeWTaJTYzLWG9KEPk6NGjTaGwqGtNOv+7Y8cOFixYALhF3oLK6mklrMVSH0gkEtX+AxJ+/YvFYolYLJYYOHBgYvr06Ynp06cnWrRokWjRooVv16j8r6a+BdXPmv61aNEisXDhwsTChQsTJSUliZKSkkRxcXGiuLg4MW7cOHOPgupnGH0tKChIFBQUJFq2bJkVY5rO/azu2S0qKkq0bt060bp168Cfler6FbpKHIvFTKRM0Ae0s00ljsViJqevDq5L3XrsscdMIHltE1Bnk0ocNLUd02T1iKOAVYktlnpAjRLWYrFkF1bCWiwRwk5YiyVC2AlrsUQIO2EtlghhJ6zFEiHshLVYIoSdsBZLhLAT1mKJEDVmnAgqjK1yWhBvYrbKeV8bNGhgcv/q/eXl5SmlFkk1jC0ejyf2913ZTG1CE7Ohr7FYLO3rZ1u4aVBU18+M5CXWZNNEjcfjZqIqjlaHhktKSszfvAW1/HzgojpR0+HH1Nf6SEYmrM7DqphxQUGByY7fvHnzCu9dt25dFQlriRbeejtCeZ4stcPuYS2WCJERCSvVVurv5s2bzWvKxBBVaSpp4t17/9jROGuMk9UKtqSGlbAWS4QI/QA7YKqQew+yB1EUKmiLYmFhIQ0aNACc6urgVHIDJ1fT9ddfD8CHH36YztenTNQOsMfj8Vof0hdRshLn5+enrWXZA+wWSz0g9D1sfn4+bdq0AdxSi2vXrg27GWkhd5Sk6ogRI2jVqhUAt912GwBNmjQBnCz5Ku2grP5Llixh9+7dFV77MZKudA2DBg0aVNlja9xzc3Nrtf/Oy8szWmS6GTErE9qEbd26NQCTJ09m6NChACxevBhwkmnLrZOt5ObmVjGePP3002bCtm3bFoBRo0YBjjtKOZpU0HjkyJEmj9WQIUMANyF1lJBhTVub2i4+jRo1Yvv27b63qy6oT61bt6Znz56AW6x7y5YtgPu87g9N8MaNG7Np0yZ/2+nrt1kslkAJzeg0c+ZMwKnWpuTZH3zwAeCWd/CiFa8u6lOYBgoFBSgYZO/evUYN6tu3L+DUvpWm8cQTTwD+1BcNy+ikMVENWAXAzJ8/3xS6qul5OuqoowCnXuwrr7yy3/cnI+gxbdiwIVdffTXgVpgfMWIEULEKfU3oPuXk5Jj+1TZDqDU6WSz1gMD3sDLQqABWIpHg3HPPBWp2d2iVysvLY8+ePQG3su5ov6O92e7du83qqn3qwoULTW1cGaTCruBdF7Q369q1K4CpCTt06NAaD2PoGXj00UcBZy/48ssvB97edNizZw8nnHAC4GpNimtPRkFBgSmhKiOqwi4TiYTv7srAJ2zlybZly5aU/JK6Sbm5uZGYsKodqodT1mDv7xMnTmTgwIEAvP3224BjgAGyzgiTDPXt1FNPBWD16tWAM6bJti6ykKombseOHQE44ogjgm5q2sRiMePFUD3cDh06ALB+/XqzIGkcJ0yYwGGHHQZgaglpq/fVV1+ZbZFfsdNWJbZYIkRgErY6Y0Ll0zjVoVVuxIgRjB8/HiCQaCi/GDBgAOBWIH/jjTeM+0fujxkzZjB37lzAlTpvvfUW4BqhspnPPvsMcMewqKgIgG+//bbKe+PxOHfeeScAv/rVrwC45pprgOyOJc7NzaV79+6AuwXQ2Pzyl780z+DFF18MOO48ubV69OgBuG6gPn36MGXKFF/bZyWsxRIhApGwc+bMqfJav379UvqsikX95je/AeD11183BivtfbPxJI+KWqki98EHH2zuw9dff23eJ1eIpMzvfvc7IPslbKNGjYyxqbKBqU2bNqxcubLCa02bNuU//uM/ALc+7NNPPx1qm9PhwAMPrPKagmKuvvpqPvroI8Ad08suu8xIVP288sorAfj000991yashLVYIoSvElYrbzIr4Pz582v8bNOmTQGn7CK4EugnP/mJ2Rcq5njFihX+NNhH3nvvPQDGjRsHOG4eWU5lKdy+fbuRUrIqv/nmm2E3NS0+/fTTKvm2ZL1fvXp1lfxcw4cPN3HV3333XYX3ZzMXXnihCXLQ+El7+Pjjj81rspAvWrTIvCaX3ZFHHgnAz372MyZPnuxr+3ydsBoYLzIe1UQ8Hjc3RZNem/uePXsadXPChAmAYxgIurZsbdECo1jioqIi45vVz/z8fOPikfpUk48vGzj88MMB6Natm5mU+nn33XcDzlhpouqhveCCC8wYyQ+tcUwWCB+Px813yJi1detW/ztUDbp2ly5dTKTTa6+9BrhJFfLy8jj99NOBiuOndsov3a1bNwDeeeedlJIF1qqdvnyLxWIJBV9iieVQT3ZqQy6NZC4ZuUJmz55dIdUpUGE110q9atUqwInN1bWStV+rWnl5eVYdds7PzzcuEKn5v/3tbwHX6Z4O6cQS7y/VqNonzadx48bm/dreXH755QBs27bNuELuu+8+ANq3b19FhZamsXv3bhNFpJ+bNm0yMcp//etfgeTxt0HFEkvTOeWUU/jkk08AJ1DiX98FOFK4c+fOgHt/Fi1aRJ8+fQCYPn06AM2aNQOguLg4qRErFWwsscVSD/BlD/vUU09V+zfp+nLT3H777ebEilauZOhvsVjMSPBly5aZv+8ngXiKLQ8H9WX06NFmf6ZQtc2bN2ekLTVpJh06dGDRokWAKwETiYTZy8kwKBfWzTffbML3vFK18vhqHBV766VVq1ZMnToVqP3JFj9QW5cvX2722JXbX15eboxNXsOnTp9JmxTnnHOO7+30ZcJKhVEDvYOmwXn44YfrfB1N/mzO1uA9tCBL8AMPPAA4E1b35tNPPwXchz8sUlnMunTpYvzF3oVTD+Svf/1rwLXsy9BU+Tq6Vk0Ls9ixY0eF+OuwUNsU033aaafx+uuvA64lWNbt8vJy8+zJMhyLxUzkV+WtoSayn1iV2GKJEL4eYFe6lDVr1lTJf5SMVFbg8vJyY7AaPXo0AM8//3xK7QnzALsk58SJEwG46KKLjIFJpznAXX0lnfyQKn4fYI/H48YVI7dOLBYzqmrl8fJqVBpTr5FRv3sNi/qOF198EXCig77//vv9tt/PMY3FYsbYJEPRn/70J5PWRdsVRWitXLnSqMvqZ15eHjNmzABcI6rSHSlqLx2s0cliqQf4GjghnT0/P9+spjL3//73vwcc075Sb2if5F2htRprlduxY4cxfOgc5quvvpp1UTPXXnst4EY6JRIJDj30UPM7ONqCUqlkc1WA8vJyevXqBWAidRo0aGBcGl26dAFc7aBJkyYmKMJ7LlZj9PnnnwNuNNgf//hHtm3bBlAlGCMM9GwWFBSYgBelf7n44otN/yR1pVmUlJRU0QoPPPBAY3yTQdHvEzoV2h7YN1ssFt8J7DysVlq5BxTSVVBQYNwzBx98cJXPadVeuHAh4IR3nXTSSYDrxO/bt685V6rrZDrXrUISte/ZsmWLcYO0b98ecKSVVt9Mt3d/qH0695kMSZmGDRsaa/cZZ5wBOOOs/eG7774LwP333w9kvnKd7CplZWVVTtNs3brVnPv1vg8qupu8oYzSFGWf+OqrrwJre+iJxPfs2WNiL5WCA9wHRFE0F1xwAeCoxoqeSUblWrNhTwRdV4OqrIlr1641eYsUT71gwQKjCstFoocgHo97I7SA7PMnV0bt2759u4lS+sUvfgE425x169YB7nYoE24bL5Xj1Kt7VvR6TdF0eu3oo4+uEqX3xRdf+NPgJFiV2GKJEBkpN3nWWWcBTgwxOE5rrXpXXXUV4MZx7o9krqFUHPV+oWtJikpy9urVy6iEOsW0ZcsWjjvuOAAjffW3rVu3mpVah6OzXcJ60XjJmJSbm2sO8GdasorKRwD3F1GVyv0vLS01ElmGK2kZCsDwEythLZYIkREJW1xcDMC8efMAJ/2lnM9LlixJ6zu9q2EmJFPl+NNYLGbcIHLv9OjRw7g/FAQiA8WNN95o0mNGSbIKhaDKtVFaWmr6mG34EdoqKe3dr7Zr1w5wDq6DY3jz2/2YkQkr66lij1u3bl3lsHdtydRDLlVeBb6eeeYZwMk6IIux1OTVq1ebyCEhdfHtt9+O5EQVUomVm+rZZ5/NOl+5n0idnjNnjslZpcVYUWJB9N+qxBZLhMhIBfbK5OTkBOLKyES1brl1GjZsaIwQWo0LCws59thjATdqS1Xa66KmZVMFdm0JCgsLfauJ6iXbKrDn5uby3//934C7LVImzLrk0baxxBZLPSArJGxQZNtq/K9rAW78tB+HtbNJwnquUyUQxA+ybUzj8bg5H/z4448D7rntumAlrMVSD8h6CRuPx83ZUVV4SzWberatxl4kYf2oF5SNEhZc67hixmUR37p1a9oW1GwcU53qkSbhR3rW6vqZEbdOKkidys3N9fXh9hv54yrHqe6PbA/+9wMJAy2w8kcvXLjQ93y9mcQPFThVrEpssUSIGlVii8WSXVgJa7FECDthLZYIYSesxRIh7IS1WCKEnbAWS4SwE9ZiiRB2wlosEcJOWIslQtgJa7FEiBpjiePxeAKyM96zcmZE71Gu2lZgVz8hO/rqjbOtHHPr/b/niJ6vwf/e6uzefM/efFXev4VZzzXV4P+wxjRZtk5vKcqa6vAmG9P9Pbs1TthseHirQ23TiZC6tDXb+llTQjnv/4M6QJDs+t7zrbU96JAJgh5T772o7n5U14a6tC1rT+vsj8qnZLw3LdsmYFCE2c9kuZ5/LPc5GSrjEYvF0k4cmE7VCruHtVgiRGQlbLYUwarvZKIcZBTQ/fBj/16bZ9hKWIslQmTFhFVdmh878XjcVLELsz6Qpfbs27ePffv2+Z2W1/yrjqyYsBaLJTWyIgnbzJkzadWqFQDdunXz7XuzMWFXdRQUFNCkSRPALWWS6gqerUnYgiBKY1oXqutnRidsixYtAKdos9rx6KOPAnD55ZfX+fuzcXCl6qquUGFhIQBHHHEEffr0AaBly5YAHHPMMaY+T01kw4Q9+eSTAXjkkUcAaN68uTHIzJ07F4BTTjmlztfJljFVJs+OHTua5HIqBDZ16lTAMUjpuZYbKJFIpJT10+YltljqARmVsKrktnDhQhNm179/fwDmz59f5+/PltX4oIMOAuCFF17giCOOAFxnuVbbPXv2mOpnMvO/9957KUmlTEvYtWvXmty80hjmzZtHjx49AKdqH8CKFSsAGDZsWNrXyvSY9u3bF8CUBl27di1dunRR23RtABYtWmS2OSpBuXXr1pRqDlkJa7HUAzIaOHH88ccDThZ8ZfX/+uuvM9ii9NGqqtX2ySef5Kc//Sng7l+SIc2isLDQ/C7pe/fddwfWXj9Q9v78/Hy+/fZbAA455JBq3y9NY/HixUb6RgGNx7x58+jduzfg1jG++eabTT1YaU833XQTAL169WLnzp2AW7WirhX9Qp+w8XjcqAnjxo0DnM25Hmo/yhyEiSbZX/7yFwDOO+88oOZJCq4qrIBx7/tVlX3lypW+ttUvtF3Jz88HHFWwpokqduzYATiTeuzYsQA89dRTAbXSP7RN6927tylcLUOTt0yoxktqc69evcy4+lV606rEFkuECE3CFhQUAHDttddy3HHHAW6RpFgsxqZNmwA48MADAUwx5GwmFosxc+ZMAI466ijzWnWUlpaaVXj58uUA/OQnPwGgXbt2xmghl4H8sdnCWWedBWDcT0JHHPfH0KFDAafYtbZD2SxhNZaTJ08GHHfNVVddBSQvwC1t64YbbjD/13c0bNgQgG3bttWpTVbCWiwRIjS3jlafWCxm9j433ngjAJdccgmNGjUCoHHjxoA/p0OCdgHcfffd3HLLLYBrmPBc2+xPtS8fPny42cedeuqpAFx22WUAtG7d2nz2/vvvB2D8+PEpVUYLw63TvHlzs3+TRJWW0LVr15S+Q4EUOTk5fPbZZwAMGDCgVu0I062j4BYZ11555ZWkz2XlzBteLUuf1fOd6uke69axWOoBoe1hvekzKq8yBx10kLGiReHcpcz3t9xyi1ld1T8VLZ4wYQKzZs0CnAAI/U3SSauw9vYXXXSRcWk99NBDQHZZzNu2bVvl3OY333xT42fUR+3FpWWBG8qYjajdS5cuBWDZsmVA8mczFotVmypn165dRrL6dW47o37Y3/zmN+Z3qcnZTPPmzQGMoSkej5uF5pVXXgHgjjvuABx1UYPkHWgN7pIlS8x3gOMCkOFND3h1Sbwywddff83LL78MwJlnngm4RsNhw4bx7rvvAhi/YywWY8qUKYC7zRErVqwwfc1GNCYyECarFq+IrmTuGm17NFl9bZvv32ixWAIjIxJ28ODBQEWpKldPtlJUVMSiRYsAV40tKyvj73//O+CeLko1pYrUw5EjRwLQr18/o4qNGjUKwHx3NrBjxw7OP/98AFatWgU4J1UAxowZQ6dOnQB44oknADj77LNNP9QvbYX8PEIZBNKMpC140dgrcsmLNCNpYkFgJazFEiW8aSkq/wMSfv9r2rRpori4OFFcXJwQxcXFidzc3ERubq6v16qpb6n2MxaLJWKxWGLGjBmJ8vLyRHl5eaK0tDRRWlqamDVrVqKwsDBRWFiYUntycnISRUVFiaKiosRLL72UeOmllxI7d+5M7Ny5M1FWVma+d+7cuYm5c+cmOnbs6Gs/gxrTZPdrw4YNZnx37dqV2LVrV6Jhw4aJhg0bZnxM0/3Xv3//xO7duxO7d+82fSsvL0+8+uqriVdffTWUZzc0lVjxldOnTzexxNrML1iwINTs8bXhsMMOA+CEE06okkf2gAMOMGq9rMNeKgfzDxo0yBhilGHDazmVGq1D6wqojyI6hA9uooJk9ygKXHPNNYDjF6/sFXjwwQcrGE+DxqrEFkuECFzCyvx93333AY6JX1JGB9j/8Ic/1Cr7eRhIml577bVA1UgmcHyTksALFiwAXCnZoEEDcyLl3nvvBZwYYa9E9VJeXm5cBBdccAGQ3aUwqkPRUF6iKjoGfXAAABACSURBVFmlFT7wwANAxQgmxQTfeuutobrerIS1WCJE4BJWkun9998HYM6cOWYVlntnypQp5pROtqH9lxettLt37+b6668HnAPrgDm0PnbsWHOYvaYTPJI+c+fO5Ve/+hUAxcXFAKGu3HVF6W28e9cgAgfCQDaW2bNnAxXHT2MirSmVhGp+YiWsxRIhApew2pc9+OCDgHPe9aKLLgLcdCJbt241J/PTrQQWFB9//DHgBDho/6lVNScnh4EDBwLuiZXu3bsD7t7dS2lpqTnnq0CLdevWARUt5VHcu1aOe165cqUJ0YsakyZNAqpmDUkkEsyZMweA119/3bwWJqEfYO/VqxennXYa4KrLjRo1yrqJKrTglJSUkJeXB7gTNi8vz/zeq1cv81plPv30U8CZ9FF21VTHtGnTqhxi18H8qBGPxzn66KMBdzJ6Cy7/3//9H4CJegu9fRm5qsViSYvQjE4yKvXu3dtIU6l+c+bMyVq3jjd2VCqx94icDp4nk6w6wTNixAggfANFWCgeGtwx9SvpWCb47rvvAOjQoUOF12OxGLfeemsmmmSwEtZiiRCBS1hJTK28hYWFtG/fHnClWNOmTbO2vOLatWsBR2JoT+NN11ldIMTSpUsZPXo0UH8l6xlnnFHltRkzZmSgJf4Ri8WqTVuzc+fOjD+ngU9YPeTKpvCHP/zB+LmuvvpqwCmG1a5dO2D/WQzCQguN1NrZs2ebiSr199577+Xss88GXN/dnXfeCcA999yTNep9UHgnrBbku+66K1PN8YVYLFYlqk19u/322zMetWVVYoslQmSkGNagQYMA15eVk5NjDjWvWbPGt+sEnWEvPz/fFKv66KOPADKS+iTsYlhSC70ahCSPIp6CIugxHTVqFE8//bSuBbiH8i+99NJ0vjItbNZEi6UekBEJqz3gM888AzhJzSZMmAD4G+UT9Gqck5NTJfopE/G/YUvYxYsXA25UF0DPnj0r/C0oghpTRTVt27bN7GEVJHHiiSfWqo1+YCWsxVIPyIiE1QqmVW3fvn2BWFTDyBLvDVtL5b1BSOCwJKzGbcyYMQD8/ve/B5z8zEoYF3TmkKDGVGezX3zxRbMPV+BEJqz91fUzoxXYgybT1bqFN0JKg68HO8ySJODP4lQ5Ki3MbUBQY6rcyS1btjSRTqm4cMJehK1KbLFEiBolrMViyS6shLVYIoSdsBZLhLAT1mKJEHbCWiwRwk5YiyVC2AlrsUQIO2EtlghhJ6zFEiHshLVYIkSNKWJycnKcQptuzc1I4DlgnVLcqfoZ1ZQutYkljuqYilT7Go/HTT+jSHX9rHHCqrNR63Rt2xvViZoOP5a+Ru2ZTZWUJuz+kESrfJrD+x3en/X1ZlosQWP3sBZLhPAlzakkqs59Nm7c2JwllAqmn7m5uezZs6fCa1biWiypYSWsxRIh6ixhvZnQi4qKAGjbtq1Jui3pq+LGnTp1MgnL5s2bBzhZ8qNamrAybdu2BWDYsGEceeSRgFtScuLEieb3+kQsFjPaVWWNqj7QtGlTAB566CFTtWL+/PmAk1pGlQtVT2jYsGFAMAnprIS1WCKELzmdJGWVF+fggw82f1Od0BYtWgCOpFUC8VNPPRWAjRs3Gsnz5JNPAv6s0GEmYbvnnnsA+M///E/AqXmrFVdaxtKlS3n44YcBmDx5crqXrEJYOZ1UgXDlypWAq1Hl5OSY8dL92Lp1K2+++SbgJOf2izDzdD3++OMAXHLJJSm9X/dg27ZtABx00EHGXlNbQknC5p24Z511FoApxzhz5kwAPvvsM/P+Zs2aATB48GCGDBkCuBP8mGOOAeqWhS+Mwe3Tpw+AqcytTJBlZWVm4HSP9YADrF+/HoBDDz0UqNsCFcaE/etf/8rYsWPT+aihY8eOAKxevTrt7whjTKXiLly4MNn1ATcP9Q8//GDGTkLphRdeAJxKAdu3b0+rDTYJm8VSD/C1ep1Wn7KyMo499lgAunbtCsCjjz4KUEFFkBr83HPPmepv/fr1A+CNN94AMJI3W7n99tsBV7JqtV2zZg3PPfcc4Pb5yiuvNP3UtkH9HDp0aHiNrgWqefRv//ZvtfpcIpGoUppRFQwnTZrE5Zdf7kv7guC0006r8H9J05deesmox1u3bjV/V4Hve++9F3Ddm+mqwzVhJazFEiECqQ87ZswYY1BSNbqdO3dW+/6ysjI+/PBDAG688UYAvv322yCa5isdO3Y0e3UhLWPLli289dZbAPTv3x9wjBGSsDJEaZ+bTeTn5xvNRlpCTYWME4mEGd//+Z//AZyKb9oLqoaSbBbjxo1j0qRJACxYsCCAHtSN5s2bA27hbj3LqrVTGWlVGlON92GHHcaXX37pa9t8nbBq8A033GAsxrIo7s94JCPMs88+C7jGqmxED++yZcuqPMgavDZt2hg1Uv643bt3m2JfJSUlgDOo2YKMYtddd51R9TWmZWVl3HDDDQB88cUXgKsKHn300fzxj38EnIVKaMsj6/J1110HOEWvtUDrb9lSpT4nJ8f065FHHgGqn6hCi7C2RfLVrlq1yvf2WZXYYokQvkpYbbZLS0vNyrxs2bJafVZS6f333/ezab5y2223Ae6KCq5klRl/3bp1RmL16NEDgGnTppn+yeikLUNQNVpqg8bgnHPOMQaTd999F4Azzzyz2vbJ31odehZOOukkAAoKCsx3FRcXA3DIIYdUMORking8bsqh/vnPf07pM4pu0/bo9NNPB1wtytf2+f6NFoslMAJx6zz22GOcd955gGs8ys/PBxxJJMmkVTyRSJjVXRv9bHRzqI0yyHjP9moP/vHHHwOOxOjcuTPglDAEp++SIo0aNQJg+fLl5rsyjQxg/fv3N9pBXaSe7BjffPMN4O71wO3vpk2bAMcglQ0Stry83AQ+qP01lRSNxWK0bNkSgPPPPx9IHnDhF1bCWiwRwtfQRO1VOnXqRKdOnQDXxN2uXTsAPvzwQ2Mxnj59OuCsXAUFBYBrkZP1cMCAAWafU1v8DmPT3kbtadiwodEItFfX/zt27GhcHc8//zzgSOgrr7xS1wTcfu7duzeVJiQlrFji2jBnzhyOOOKIav8uq/Dxxx8PwEcffZTS94YRmqhnsW/fvoATEwxOzHtlTXDUqFGcfPLJAJxyyikApr5sXUgrp1O6bNy4kY0bNwKuX04b8169epkoF+9ioRvxz3/+E4Dhw4cD0L17d6NmZvrIVps2bQDXnQHug6f+aeLt2LHDHGSYNm0aAA8++CANGzas8LnCwsIKn4squifaGsiX6UXjt2XLFqN2pjpRw0RbNRmN7rvvPgA6d+5sxk3bOm9El6LC/Jiw1WFVYoslQvgqYb2uDa2wS5cuBVyDw29/+9sqrp5YLMa5554LuJJVcadDhgzh888/B2qOlgoDqa+bN282/9dKu3btWgAT2XLNNdcYaSNN4sknn+TMM88EXPVah6O9AQdRIycnxwQJeCVr5UQFo0ePBpyD3tLAshk9p950Rxpvb+JB/f7OO+8AcMsttwCOdum3MdFKWIslQvhqdBI5OTkccMABgLu3k2lfqxVg9nPTpk0zBgrtV3Uqwmtwqu0e1m8DhfZpCnr43e9+Z0ILdd73lVdeAeCTTz4xYYji+OOPN/HF2rPPmjULcML70iXTRqdHH32UX/7ylxVeW79+vTE8et13Il3JE+YBdklOxUCfeuqpxo4xZswYwAksGTduHIB55mV8HT9+vAnnrC2hHGAXzZo1o3fv3oDz4ELFWFF1SAam7t27Gx+cLHNSietCUIOr9h977LHmULb6t2HDBsCZiFqcNNGHDx/OlClTKnyHrI3yy6ZDpiasfLXbtm0z/VGf+/fvb7YH3jzVEM5hffXT7wiyyrHjsVjMTNQJEyYAbsTT3r17zaKl7COpYg+wWyz1AF+NTlp9XnzxRRPZNHjw4Crvk2FCZnBw1SYZavRdUh2hbuligqBHjx4mRYwkrLJDduvWzWgQisft3LmzUZMldeTWKSoqyrhRLVWkFsooE4/HjVvqwQcfBNwILnDHW5FUQcTYVsYbnVRTpFJtqfwdiUTCaEmXXnopADfddBPgRD4pjnzu3Ll1vjZYCWuxRApf97CKECkuLjZ6/RNPPAFgInzatWtnTuJ4sytKQsnprLyvDRo0YOrUqYCTCKw2BG2gGDhwIK+++irg7lMlOePxuNnP6TTLU089ZfY50i4kcSdNmsRVV12VTjNC2cM2atTIjI32rl7JJQly1FFHARX3qXKFSEOqi6Sr7ZjG4/HQi7rpWejTp48Z30WLFgGpn/u1e1iLpR4QiJV448aNJshAaI+Tm5trpFCyfUZlSktLjcvkhBNOqFU7gpawrVq1MtZs7dm9dYNkJR0/fjzgnPGV1VBJ6ZRZ44orrjAhjLUlSAkr6Zhs3ylp8dprr3H22WcDVHFl+Y2fYxqPx814KJBl+fLlNUpBPbuaN/F43GgTega0Z7/gggvMPFAwRap2mFBjibt3726C+OWnVGf+1ZgKP8vLyysYl/QaOEeVVPog29iwYYNJgdO9e3fA3RaUlpaabYFM+ps3bzYP/kMPPQTAf/3XfwHwt7/9jZdffhkIJtteuihVjBeNm9T7m266KaWJqod95MiRXHHFFYCbgH3GjBm+tLc2NG7cmA8++ABwA/wTiYRZhCdOnAg4CzM4C5TGTwKoX79+DBo0CHD9sIovSCQS5vjgnXfeCdTdcGpVYoslQgSiEntRBIzM/YWFheaEhgxLU6ZMMZE+MmzoSNr+VqSaTPZhHsVSqhfvVkCrseKk33vvPaN6STrpoH8sFjOGm4EDB9aqDUGqxDrEvWXLFnOPFR8+YsQIwAlykRpZ2W0FrvTSFkESCFw32IoVK1Jqj59jmpuba+653HP7o3LQhzeWONl7f/jhB4AqW8T9YY1OFks9IHAJKxRTXFxcbCRP0Gb2MONOZTzSqRVJXnATyt1xxx2mCJYqInhXZxmikp0Xrokw3DqtWrUyqUmVvlSSs02bNia0UpJ2165d5iRSMgmkZ0CnuFLdt/s9ptIEdM/Hjx9fwd6SDhq3WbNmmVRHtS2nGmoscbYQ5oStzIABA7j11lsBV91q2rRp0oPd4OQulg+ztgWUwool1gENWe31YNeUZDwZp512mqlgWFvCHFMVt9I2ZvHixSYyTa+tW7fORHAp0kk+V6nD6WBVYoulHhCIW8dvahsLWtsVPwjmzZtnjDKKDPrggw+qqIkywA0ZMiTr08SoNKbU3lRVRyUgUH6vqFA5l5iO2WUSK2EtlgiR9XtYr3sg0wfY/UBuEu1TfTpBEsoeVlqBN15aPyVtdeKovLw8EKNiNo5pENg9rMVSD8h6CZtqxoBk+9wf+2qcjB9LX+trP7Pe6JQNJSzqE16DXLbe28opZbK1nZnAqsQWS4SoUSW2WCzZhZWwFkuEsBPWYokQdsJaLBHCTliLJULYCWuxRAg7YS2WCPH/t+eEUxWBzosAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 에포크 29 에서 걸린 시간은 128.80401611328125 초 입니다\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-ec94c20bab2b>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataset, epochs)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# GIF를 위한 이미지를 바로 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfM4YcPVPkNO"
   },
   "source": [
    "마지막 체크포인트를 복구합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XhXsd0srPo8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2af57932508>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P4M_vIbUi7c0"
   },
   "source": [
    "## GIF 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WfO5wCdclHGL"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'image_at_epoch_0050.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-8d1c17b31675>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mPIL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'image_at_epoch_{:04d}.png'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_no\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdisplay_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-30-8d1c17b31675>\u001b[0m in \u001b[0;36mdisplay_image\u001b[1;34m(epoch_no)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 에포크 숫자를 사용하여 하나의 이미지를 보여준다\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdisplay_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_no\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mPIL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'image_at_epoch_{:04d}.png'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_no\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdisplay_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tf20\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2808\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2809\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2810\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'image_at_epoch_0050.png'"
     ]
    }
   ],
   "source": [
    "# 에포크 숫자를 사용하여 하나의 이미지를 보여준다\n",
    "def display_image(epoch_no):\n",
    "    return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))\n",
    "\n",
    "display_image(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-TMHTuisnm4J"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "99-93.DCGAN.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
